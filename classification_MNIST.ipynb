{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow.examples.tutorials.mnist.input_data as mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input():\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x_in\")\n",
    "    y_ = tf.placeholder(\"float\", [None, 10], name=\"y_out\")\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    return x,y_,x_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init)\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        \n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init)\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        \n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024 )\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, out_model):\n",
    "    return -tf.reduce_sum(y_ * tf.log(out_model))\n",
    "\n",
    "def optimize(loss_tmin):\n",
    "    loss_optimize = tf.train.AdamOptimizer(1e-4).minimize(loss_tmin)\n",
    "    return loss_optimize\n",
    "\n",
    "def get_acc(y, out_model):\n",
    "    state_y = tf.equal(tf.argmax(y,1), tf.argmax(out_model,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x0000003E57C309B0>\n"
     ]
    }
   ],
   "source": [
    "print(x.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "# accuracy = get_acc(y_, out_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = mnist.train.next_batch(50)\n",
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.296875\n",
      "step 101, training accuracy 0.953125\n",
      "step 201, training accuracy 0.953125\n",
      "step 301, training accuracy 0.953125\n",
      "step 401, training accuracy 0.984375\n",
      "step 501, training accuracy 0.96875\n",
      "step 601, training accuracy 1\n",
      "step 701, training accuracy 1\n",
      "step 801, training accuracy 0.953125\n",
      "step 901, training accuracy 1\n",
      "step 1001, training accuracy 0.984375\n",
      "step 1101, training accuracy 0.984375\n",
      "step 1201, training accuracy 1\n",
      "step 1301, training accuracy 1\n",
      "step 1401, training accuracy 0.984375\n",
      "step 1501, training accuracy 0.96875\n",
      "step 1601, training accuracy 0.96875\n",
      "step 1701, training accuracy 0.984375\n",
      "step 1801, training accuracy 1\n",
      "step 1901, training accuracy 0.96875\n",
      "test accuracy 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    print(\"test accuracy %g\" % accuracy.eval(\n",
    "    feed_dict={x: mnist.test.images[0:100], y_: mnist.test.labels[0:100]}))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[0:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('samples_DCgan_final.pkl', 'rb') as f:\n",
    "    pic_generate = pickle.load(f)\n",
    "    \n",
    "pic_in = pic_generate.reshape(-1,28*28)\n",
    "pic_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('label_DCgan.pkl','rb') as f:\n",
    "    pic_label = pickle.load(f)\n",
    "\n",
    "\n",
    "pic_label_1h = np.zeros((100,10))\n",
    "pic_label_1h[np.arange(100), pic_label] = 1\n",
    "\n",
    "pic_label_1h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.28125\n",
      "test accuracy 0.1\n",
      "step 101, training accuracy 0.953125\n",
      "step 201, training accuracy 0.953125\n",
      "step 301, training accuracy 0.96875\n",
      "step 401, training accuracy 0.96875\n",
      "step 501, training accuracy 0.921875\n",
      "test accuracy 0.31\n",
      "step 601, training accuracy 1\n",
      "step 701, training accuracy 0.96875\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.96875\n",
      "step 1001, training accuracy 0.984375\n",
      "test accuracy 0.37\n",
      "step 1101, training accuracy 0.984375\n",
      "step 1201, training accuracy 1\n",
      "step 1301, training accuracy 0.953125\n",
      "step 1401, training accuracy 0.96875\n",
      "step 1501, training accuracy 1\n",
      "test accuracy 0.38\n",
      "step 1601, training accuracy 1\n",
      "step 1701, training accuracy 1\n",
      "step 1801, training accuracy 1\n",
      "step 1901, training accuracy 0.984375\n",
      "step 2001, training accuracy 1\n",
      "test accuracy 0.41\n",
      "step 2101, training accuracy 0.984375\n",
      "step 2201, training accuracy 0.984375\n",
      "step 2301, training accuracy 1\n",
      "step 2401, training accuracy 1\n",
      "step 2501, training accuracy 1\n",
      "test accuracy 0.4\n",
      "step 2601, training accuracy 0.96875\n",
      "step 2701, training accuracy 0.96875\n",
      "step 2801, training accuracy 0.984375\n",
      "step 2901, training accuracy 1\n",
      "step 3001, training accuracy 0.984375\n",
      "test accuracy 0.39\n",
      "step 3101, training accuracy 0.984375\n",
      "step 3201, training accuracy 1\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 1\n",
      "step 3501, training accuracy 0.984375\n",
      "test accuracy 0.39\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 1\n",
      "step 3801, training accuracy 1\n",
      "step 3901, training accuracy 0.984375\n",
      "step 4001, training accuracy 1\n",
      "test accuracy 0.38\n",
      "step 4101, training accuracy 0.984375\n",
      "step 4201, training accuracy 1\n",
      "step 4301, training accuracy 0.984375\n",
      "step 4401, training accuracy 1\n",
      "step 4501, training accuracy 1\n",
      "test accuracy 0.39\n",
      "step 4601, training accuracy 1\n",
      "step 4701, training accuracy 1\n",
      "step 4801, training accuracy 1\n",
      "step 4901, training accuracy 1\n",
      "step 5001, training accuracy 1\n",
      "test accuracy 0.39\n",
      "step 5101, training accuracy 1\n",
      "step 5201, training accuracy 1\n",
      "step 5301, training accuracy 1\n",
      "step 5401, training accuracy 1\n",
      "step 5501, training accuracy 1\n",
      "test accuracy 0.36\n",
      "step 5601, training accuracy 0.984375\n",
      "step 5701, training accuracy 1\n",
      "step 5801, training accuracy 1\n",
      "step 5901, training accuracy 1\n",
      "step 6001, training accuracy 0.984375\n",
      "test accuracy 0.36\n",
      "step 6101, training accuracy 1\n",
      "step 6201, training accuracy 1\n",
      "step 6301, training accuracy 0.984375\n",
      "step 6401, training accuracy 0.984375\n",
      "step 6501, training accuracy 1\n",
      "test accuracy 0.38\n",
      "step 6601, training accuracy 1\n",
      "step 6701, training accuracy 1\n",
      "step 6801, training accuracy 1\n",
      "step 6901, training accuracy 1\n",
      "step 7001, training accuracy 1\n",
      "test accuracy 0.34\n",
      "step 7101, training accuracy 1\n",
      "step 7201, training accuracy 1\n",
      "step 7301, training accuracy 1\n",
      "step 7401, training accuracy 1\n",
      "step 7501, training accuracy 1\n",
      "test accuracy 0.34\n",
      "step 7601, training accuracy 1\n",
      "step 7701, training accuracy 1\n",
      "step 7801, training accuracy 0.984375\n",
      "step 7901, training accuracy 1\n",
      "step 8001, training accuracy 1\n",
      "test accuracy 0.31\n",
      "step 8101, training accuracy 1\n",
      "step 8201, training accuracy 1\n",
      "step 8301, training accuracy 1\n",
      "step 8401, training accuracy 1\n",
      "step 8501, training accuracy 1\n",
      "test accuracy 0.29\n",
      "step 8601, training accuracy 1\n",
      "step 8701, training accuracy 1\n",
      "step 8801, training accuracy 1\n",
      "step 8901, training accuracy 1\n",
      "step 9001, training accuracy 1\n",
      "test accuracy 0.37\n",
      "step 9101, training accuracy 1\n",
      "step 9201, training accuracy 1\n",
      "step 9301, training accuracy 1\n",
      "step 9401, training accuracy 1\n",
      "step 9501, training accuracy 1\n",
      "test accuracy 0.36\n",
      "step 9601, training accuracy 0.984375\n",
      "step 9701, training accuracy 0.984375\n",
      "step 9801, training accuracy 1\n",
      "step 9901, training accuracy 1\n",
      "step 10001, training accuracy 1\n",
      "test accuracy 0.31\n",
      "step 10101, training accuracy 1\n",
      "step 10201, training accuracy 1\n",
      "step 10301, training accuracy 1\n",
      "step 10401, training accuracy 1\n",
      "step 10501, training accuracy 1\n",
      "test accuracy 0.33\n",
      "step 10601, training accuracy 1\n",
      "step 10701, training accuracy 1\n",
      "step 10801, training accuracy 1\n",
      "step 10901, training accuracy 1\n",
      "step 11001, training accuracy 1\n",
      "test accuracy 0.35\n",
      "step 11101, training accuracy 1\n",
      "step 11201, training accuracy 1\n",
      "step 11301, training accuracy 1\n",
      "step 11401, training accuracy 1\n",
      "step 11501, training accuracy 1\n",
      "test accuracy 0.36\n",
      "step 11601, training accuracy 1\n",
      "step 11701, training accuracy 1\n",
      "step 11801, training accuracy 1\n",
      "step 11901, training accuracy 1\n",
      "step 12001, training accuracy 1\n",
      "test accuracy 0.28\n",
      "step 12101, training accuracy 1\n",
      "step 12201, training accuracy 1\n",
      "step 12301, training accuracy 1\n",
      "step 12401, training accuracy 1\n",
      "step 12501, training accuracy 1\n",
      "test accuracy 0.28\n",
      "step 12601, training accuracy 1\n",
      "step 12701, training accuracy 1\n",
      "step 12801, training accuracy 1\n",
      "step 12901, training accuracy 1\n",
      "step 13001, training accuracy 1\n",
      "test accuracy 0.33\n",
      "step 13101, training accuracy 1\n",
      "step 13201, training accuracy 1\n",
      "step 13301, training accuracy 1\n",
      "step 13401, training accuracy 1\n",
      "step 13501, training accuracy 1\n",
      "test accuracy 0.32\n",
      "step 13601, training accuracy 1\n",
      "step 13701, training accuracy 1\n",
      "step 13801, training accuracy 1\n",
      "step 13901, training accuracy 1\n",
      "step 14001, training accuracy 1\n",
      "test accuracy 0.33\n",
      "step 14101, training accuracy 1\n",
      "step 14201, training accuracy 1\n",
      "step 14301, training accuracy 1\n",
      "step 14401, training accuracy 1\n",
      "step 14501, training accuracy 1\n",
      "test accuracy 0.32\n",
      "step 14601, training accuracy 1\n",
      "step 14701, training accuracy 1\n",
      "step 14801, training accuracy 1\n",
      "step 14901, training accuracy 1\n",
      "step 15001, training accuracy 1\n",
      "test accuracy 0.25\n",
      "step 15101, training accuracy 1\n",
      "step 15201, training accuracy 1\n",
      "step 15301, training accuracy 1\n",
      "step 15401, training accuracy 1\n",
      "step 15501, training accuracy 1\n",
      "test accuracy 0.34\n",
      "step 15601, training accuracy 1\n",
      "step 15701, training accuracy 1\n",
      "step 15801, training accuracy 1\n",
      "step 15901, training accuracy 1\n",
      "step 16001, training accuracy 1\n",
      "test accuracy 0.34\n",
      "step 16101, training accuracy 1\n",
      "step 16201, training accuracy 1\n",
      "step 16301, training accuracy 1\n",
      "step 16401, training accuracy 1\n",
      "step 16501, training accuracy 1\n",
      "test accuracy 0.32\n",
      "step 16601, training accuracy 1\n",
      "step 16701, training accuracy 1\n",
      "step 16801, training accuracy 1\n",
      "step 16901, training accuracy 0.015625\n",
      "step 17001, training accuracy 0.09375\n",
      "test accuracy 0.08\n",
      "step 17101, training accuracy 0.140625\n",
      "step 17201, training accuracy 0.09375\n",
      "step 17301, training accuracy 0.0625\n",
      "step 17401, training accuracy 0.0625\n",
      "step 17501, training accuracy 0.125\n",
      "test accuracy 0.08\n",
      "step 17601, training accuracy 0.03125\n",
      "step 17701, training accuracy 0.015625\n",
      "step 17801, training accuracy 0.109375\n",
      "step 17901, training accuracy 0.203125\n",
      "step 18001, training accuracy 0.09375\n",
      "test accuracy 0.08\n",
      "step 18101, training accuracy 0.21875\n",
      "step 18201, training accuracy 0.1875\n",
      "step 18301, training accuracy 0.046875\n",
      "step 18401, training accuracy 0.046875\n",
      "step 18501, training accuracy 0.0625\n",
      "test accuracy 0.08\n",
      "step 18601, training accuracy 0.125\n",
      "step 18701, training accuracy 0.0625\n",
      "step 18801, training accuracy 0.125\n",
      "step 18901, training accuracy 0.09375\n",
      "step 19001, training accuracy 0.078125\n",
      "test accuracy 0.08\n",
      "step 19101, training accuracy 0.078125\n",
      "step 19201, training accuracy 0.109375\n",
      "step 19301, training accuracy 0.046875\n",
      "step 19401, training accuracy 0.171875\n",
      "step 19501, training accuracy 0.171875\n",
      "test accuracy 0.08\n",
      "step 19601, training accuracy 0.0625\n",
      "step 19701, training accuracy 0.09375\n",
      "step 19801, training accuracy 0.171875\n",
      "step 19901, training accuracy 0.078125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C_regu(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        pool1 = tf.layers.batch_normalization(pool1, training=True)\n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        pool2 = tf.layers.batch_normalization(pool2, training=True)\n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.4375\n",
      "test accuracy 0.18\n",
      "step 101, training accuracy 0.984375\n",
      "step 201, training accuracy 0.953125\n",
      "step 301, training accuracy 0.953125\n",
      "step 401, training accuracy 0.96875\n",
      "step 501, training accuracy 0.984375\n",
      "test accuracy 0.55\n",
      "step 601, training accuracy 0.984375\n",
      "step 701, training accuracy 1\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.984375\n",
      "step 1001, training accuracy 0.96875\n",
      "test accuracy 0.56\n",
      "step 1101, training accuracy 0.96875\n",
      "step 1201, training accuracy 0.984375\n",
      "step 1301, training accuracy 1\n",
      "step 1401, training accuracy 0.984375\n",
      "step 1501, training accuracy 1\n",
      "test accuracy 0.64\n",
      "step 1601, training accuracy 1\n",
      "step 1701, training accuracy 1\n",
      "step 1801, training accuracy 0.96875\n",
      "step 1901, training accuracy 1\n",
      "step 2001, training accuracy 0.984375\n",
      "test accuracy 0.61\n",
      "step 2101, training accuracy 0.984375\n",
      "step 2201, training accuracy 1\n",
      "step 2301, training accuracy 0.984375\n",
      "step 2401, training accuracy 0.96875\n",
      "step 2501, training accuracy 1\n",
      "test accuracy 0.59\n",
      "step 2601, training accuracy 0.96875\n",
      "step 2701, training accuracy 0.984375\n",
      "step 2801, training accuracy 1\n",
      "step 2901, training accuracy 1\n",
      "step 3001, training accuracy 1\n",
      "test accuracy 0.6\n",
      "step 3101, training accuracy 0.984375\n",
      "step 3201, training accuracy 1\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 0.984375\n",
      "step 3501, training accuracy 0.984375\n",
      "test accuracy 0.62\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 0.984375\n",
      "step 3801, training accuracy 0.984375\n",
      "step 3901, training accuracy 0.984375\n",
      "step 4001, training accuracy 1\n",
      "test accuracy 0.58\n",
      "step 4101, training accuracy 1\n",
      "step 4201, training accuracy 0.984375\n",
      "step 4301, training accuracy 1\n",
      "step 4401, training accuracy 1\n",
      "step 4501, training accuracy 1\n",
      "test accuracy 0.62\n",
      "step 4601, training accuracy 1\n",
      "step 4701, training accuracy 1\n",
      "step 4801, training accuracy 0.09375\n",
      "step 4901, training accuracy 0.0625\n",
      "step 5001, training accuracy 0.046875\n",
      "test accuracy 0.08\n",
      "step 5101, training accuracy 0.109375\n",
      "step 5201, training accuracy 0.109375\n",
      "step 5301, training accuracy 0.015625\n",
      "step 5401, training accuracy 0.109375\n",
      "step 5501, training accuracy 0.09375\n",
      "test accuracy 0.08\n",
      "step 5601, training accuracy 0.09375\n",
      "step 5701, training accuracy 0.09375\n",
      "step 5801, training accuracy 0.140625\n",
      "step 5901, training accuracy 0.171875\n",
      "step 6001, training accuracy 0.09375\n",
      "test accuracy 0.08\n",
      "step 6101, training accuracy 0.0625\n",
      "step 6201, training accuracy 0.046875\n",
      "step 6301, training accuracy 0.09375\n",
      "step 6401, training accuracy 0.078125\n",
      "step 6501, training accuracy 0.078125\n",
      "test accuracy 0.08\n",
      "step 6601, training accuracy 0.078125\n",
      "step 6701, training accuracy 0.109375\n",
      "step 6801, training accuracy 0.109375\n",
      "step 6901, training accuracy 0.09375\n",
      "step 7001, training accuracy 0.078125\n",
      "test accuracy 0.08\n",
      "step 7101, training accuracy 0.078125\n",
      "step 7201, training accuracy 0.0625\n",
      "step 7301, training accuracy 0.078125\n",
      "step 7401, training accuracy 0.109375\n",
      "step 7501, training accuracy 0.09375\n",
      "test accuracy 0.08\n",
      "step 7601, training accuracy 0.03125\n",
      "step 7701, training accuracy 0.109375\n",
      "step 7801, training accuracy 0.109375\n",
      "step 7901, training accuracy 0.078125\n",
      "step 8001, training accuracy 0.0625\n",
      "test accuracy 0.08\n",
      "step 8101, training accuracy 0.125\n",
      "step 8201, training accuracy 0.109375\n",
      "step 8301, training accuracy 0.1875\n",
      "step 8401, training accuracy 0.0625\n",
      "step 8501, training accuracy 0.109375\n",
      "test accuracy 0.08\n",
      "step 8601, training accuracy 0.078125\n",
      "step 8701, training accuracy 0.0625\n",
      "step 8801, training accuracy 0.109375\n",
      "step 8901, training accuracy 0.109375\n",
      "step 9001, training accuracy 0.0625\n",
      "test accuracy 0.08\n",
      "step 9101, training accuracy 0.171875\n",
      "step 9201, training accuracy 0.109375\n",
      "step 9301, training accuracy 0.078125\n",
      "step 9401, training accuracy 0.046875\n",
      "step 9501, training accuracy 0.0625\n",
      "test accuracy 0.08\n",
      "step 9601, training accuracy 0.15625\n",
      "step 9701, training accuracy 0.140625\n",
      "step 9801, training accuracy 0.125\n",
      "step 9901, training accuracy 0.140625\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C_regu(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C_regu_dropconv(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1 = tf.layers.dropout(conv1, rate=0.2)\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        pool1 = tf.layers.batch_normalization(pool1, training=True)\n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2 = tf.layers.dropout(conv2, rate=0.2)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        pool2 = tf.layers.batch_normalization(pool2, training=True)\n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.453125\n",
      "test accuracy 0.17\n",
      "step 101, training accuracy 0.96875\n",
      "step 201, training accuracy 0.96875\n",
      "step 301, training accuracy 0.96875\n",
      "step 401, training accuracy 0.96875\n",
      "step 501, training accuracy 0.96875\n",
      "test accuracy 0.61\n",
      "step 601, training accuracy 0.953125\n",
      "step 701, training accuracy 0.953125\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.96875\n",
      "step 1001, training accuracy 1\n",
      "test accuracy 0.64\n",
      "step 1101, training accuracy 0.984375\n",
      "step 1201, training accuracy 0.984375\n",
      "step 1301, training accuracy 1\n",
      "step 1401, training accuracy 1\n",
      "step 1501, training accuracy 0.984375\n",
      "test accuracy 0.65\n",
      "step 1601, training accuracy 0.984375\n",
      "step 1701, training accuracy 1\n",
      "step 1801, training accuracy 0.984375\n",
      "step 1901, training accuracy 1\n",
      "step 2001, training accuracy 1\n",
      "test accuracy 0.71\n",
      "step 2101, training accuracy 0.953125\n",
      "step 2201, training accuracy 0.984375\n",
      "step 2301, training accuracy 1\n",
      "step 2401, training accuracy 1\n",
      "step 2501, training accuracy 0.984375\n",
      "test accuracy 0.66\n",
      "step 2601, training accuracy 0.984375\n",
      "step 2701, training accuracy 1\n",
      "step 2801, training accuracy 1\n",
      "step 2901, training accuracy 1\n",
      "step 3001, training accuracy 1\n",
      "test accuracy 0.64\n",
      "step 3101, training accuracy 1\n",
      "step 3201, training accuracy 0.984375\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 1\n",
      "step 3501, training accuracy 1\n",
      "test accuracy 0.63\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 1\n",
      "step 3801, training accuracy 1\n",
      "step 3901, training accuracy 1\n",
      "step 4001, training accuracy 0.125\n",
      "test accuracy 0.08\n",
      "step 4101, training accuracy 0.09375\n",
      "step 4201, training accuracy 0.125\n",
      "step 4301, training accuracy 0.125\n",
      "step 4401, training accuracy 0.09375\n",
      "step 4501, training accuracy 0.109375\n",
      "test accuracy 0.08\n",
      "step 4601, training accuracy 0.109375\n",
      "step 4701, training accuracy 0.15625\n",
      "step 4801, training accuracy 0.0625\n",
      "step 4901, training accuracy 0.125\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C_regu_dropconv(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(5000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C_regu_dropconv_m(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1 = tf.layers.dropout(conv1, rate=0.2)\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        pool1 = tf.layers.batch_normalization(pool1, training=True)\n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2 = tf.layers.dropout(conv2, rate=0.2)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        pool2 = tf.layers.batch_normalization(pool2, training=True)\n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.2))\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.4375\n",
      "test accuracy 0.16\n",
      "step 101, training accuracy 0.984375\n",
      "step 201, training accuracy 1\n",
      "step 301, training accuracy 1\n",
      "step 401, training accuracy 0.96875\n",
      "step 501, training accuracy 0.984375\n",
      "test accuracy 0.57\n",
      "step 601, training accuracy 0.953125\n",
      "step 701, training accuracy 0.96875\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 1\n",
      "step 1001, training accuracy 1\n",
      "test accuracy 0.55\n",
      "step 1101, training accuracy 0.953125\n",
      "step 1201, training accuracy 1\n",
      "step 1301, training accuracy 1\n",
      "step 1401, training accuracy 0.953125\n",
      "step 1501, training accuracy 1\n",
      "test accuracy 0.57\n",
      "step 1601, training accuracy 0.984375\n",
      "step 1701, training accuracy 1\n",
      "step 1801, training accuracy 1\n",
      "step 1901, training accuracy 1\n",
      "step 2001, training accuracy 0.96875\n",
      "test accuracy 0.69\n",
      "step 2101, training accuracy 1\n",
      "step 2201, training accuracy 1\n",
      "step 2301, training accuracy 1\n",
      "step 2401, training accuracy 0.96875\n",
      "step 2501, training accuracy 1\n",
      "test accuracy 0.63\n",
      "step 2601, training accuracy 1\n",
      "step 2701, training accuracy 0.984375\n",
      "step 2801, training accuracy 1\n",
      "step 2901, training accuracy 1\n",
      "step 3001, training accuracy 1\n",
      "test accuracy 0.63\n",
      "step 3101, training accuracy 1\n",
      "step 3201, training accuracy 1\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 1\n",
      "step 3501, training accuracy 1\n",
      "test accuracy 0.64\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 1\n",
      "step 3801, training accuracy 1\n",
      "step 3901, training accuracy 1\n",
      "step 4001, training accuracy 1\n",
      "test accuracy 0.65\n",
      "step 4101, training accuracy 0.140625\n",
      "step 4201, training accuracy 0.109375\n",
      "step 4301, training accuracy 0.015625\n",
      "step 4401, training accuracy 0.140625\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C_regu_dropconv_m(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(4501):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
