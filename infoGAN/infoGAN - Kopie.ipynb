{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow.examples.tutorials.mnist.input_data as mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os, gzip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(dataset_name):\n",
    "    data_dir = os.path.join(\"./data\", dataset_name)\n",
    "\n",
    "    def extract_data(filename, num_data, head_size, data_size):\n",
    "        with gzip.open(filename) as bytestream:\n",
    "            bytestream.read(head_size)\n",
    "            buf = bytestream.read(data_size * num_data)\n",
    "            data = np.frombuffer(buf, dtype=np.uint8).astype(np.float)\n",
    "        return data\n",
    "\n",
    "    data = extract_data(data_dir + '/train-images-idx3-ubyte.gz', 60000, 16, 28 * 28)\n",
    "    trX = data.reshape((60000, 28, 28, 1))\n",
    "\n",
    "    data = extract_data(data_dir + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
    "    trY = data.reshape((60000))\n",
    "\n",
    "    data = extract_data(data_dir + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28 * 28)\n",
    "    teX = data.reshape((10000, 28, 28, 1))\n",
    "\n",
    "    data = extract_data(data_dir + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
    "    teY = data.reshape((10000))\n",
    "\n",
    "    trY = np.asarray(trY)\n",
    "    teY = np.asarray(teY)\n",
    "\n",
    "    X = np.concatenate((trX, teX), axis=0)\n",
    "    y = np.concatenate((trY, teY), axis=0).astype(np.int)\n",
    "\n",
    "    seed = 547\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "\n",
    "    y_vec = np.zeros((len(y), 10), dtype=np.float)\n",
    "    for i, label in enumerate(y):\n",
    "        y_vec[i, y[i]] = 1.0\n",
    "\n",
    "    return X / 255., y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x,data_y = load_mnist(\"mnist\")\n",
    "data = [data_x, data_y]\n",
    "num_train = data_x.shape[0]\n",
    "shape_img = [-1,28,28,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get data from mnist\n",
    "# data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# data_train = data.train.images\n",
    "# label_train = data.train.labels\n",
    "# num_train, shape_img = data.train.images.shape\n",
    "# shape_img = [-1,28,28,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_code():\n",
    "    y_example_code = np.zeros((100,12), dtype=np.float)\n",
    "    final_codes=[]\n",
    "    for k in range(10):\n",
    "        final_codes.append(list(k*np.ones(10)))\n",
    "    final_codes = np.array(final_codes)\n",
    "    final_codes = final_codes.reshape(100,-1)\n",
    "    for i,j in enumerate(final_codes):\n",
    "        y_example_code[i,int(j[0])]=1.0\n",
    "    return y_example_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input(noise_shape, image_shape):\n",
    "    # image_shape = (num_exaple, height, width, depth)\n",
    "    \n",
    "    inputs_image = tf.placeholder(tf.float32, \n",
    "                                [None, image_shape[1], image_shape[2], image_shape[3]],\n",
    "                                 name='inputs_image')\n",
    "    inputs_noise = tf.placeholder(tf.float32,\n",
    "                                 [None, noise_shape], name='inpute_noise')\n",
    "    y = tf.placeholder(tf.float32, [None, 12], name='y')\n",
    "    return inputs_image, inputs_noise, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inputs, filters, kernel_size, strides, stddev=0.02, name=\"conv2d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        conv = tf.layers.conv2d(inputs, filters=filters, kernel_size=4, strides=strides, \n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "                         bias_initializer=tf.constant_initializer(0.0),padding='same')\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_transpose(inputs, filters, kernel_size, strides, stddev=0.02, name=\"conv2d_transpose\"):\n",
    "    with tf.variable_scope(name):\n",
    "        conv_transpose = tf.layers.conv2d_transpose(\n",
    "                         inputs=inputs, filters=filters, kernel_size=kernel_size,strides=strides, \n",
    "                         kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "                         bias_initializer=tf.constant_initializer(0.0),padding= 'same')\n",
    "        return conv_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(inputs, output_dim, stddev=0.02, bias_start = 0.0):\n",
    "    dense = tf.layers.dense(inputs=inputs, units=output_dim, \n",
    "                   kernel_initializer=tf.random_normal_initializer(stddev=stddev),\n",
    "                   bias_initializer=tf.constant_initializer(bias_start))\n",
    "    return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn(x, training):\n",
    "    return tf.contrib.layers.batch_norm(x,\n",
    "                                        decay=0.9,\n",
    "                                        updates_collections=None,\n",
    "                                        epsilon=1e-5,\n",
    "                                        scale=True,\n",
    "                                        is_training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x, share = False):\n",
    "    with tf.variable_scope(\"classifier\", reuse=share):\n",
    "#         x = tf.Variable(tf.random_normal([10, 100], stddev=0.35),\n",
    "#                     dtype=tf.float32)\n",
    "        h_c1 = linear(x, 64)\n",
    "        h_c1 = bn(h_c1, training=(not share))\n",
    "        h_c1 = tf.nn.leaky_relu(h_c1, alpha=0.2)\n",
    "        \n",
    "        logits = linear(h_c1, 12)\n",
    "        out = tf.nn.softmax(h_c1)\n",
    "        \n",
    "        return logits, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_g =tf.Variable(tf.random_normal([10, 100], stddev=0.35),\n",
    "#                     dtype=tf.float32)\n",
    "# yy = data_y[0:10].astype(np.float32)\n",
    "# tf.reset_default_graph()\n",
    "# kk = classifier(in_g)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     a = sess.run(kk)\n",
    "#     print(a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_img, y, num_output, alpha=0.01, share=False):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=share):\n",
    "        noise_img = tf.concat([noise_img, y], axis=1)\n",
    "        \n",
    "        h_g1 = linear(noise_img, 1024)\n",
    "        h_g1 = bn(h_g1, training=(not share))\n",
    "        h_g1 = tf.nn.relu(h_g1)\n",
    "        \n",
    "        h_g2 = linear(h_g1, 128*7*7)\n",
    "        h_g2 = bn(h_g2, training=(not share))\n",
    "        h_g2 = tf.nn.relu(h_g2)\n",
    "        \n",
    "        h_g2 = tf.reshape(h_g2, [-1, 7, 7, 128])\n",
    "        \n",
    "        #7*7*128 t o 14*14*64\n",
    "        h_g3 = conv2d_transpose(inputs=h_g2, filters=64, kernel_size=4, strides=2, name=\"g_deconv1\")\n",
    "        h_g3 = tf.layers.batch_normalization(h_g3, training=(not share))\n",
    "        h_g3 = tf.nn.relu(h_g3)\n",
    "#         h_g3 = tf.layers.dropout(h_g2, rate=0.2)\n",
    "        \n",
    "        # 14*14*64 to 28*28*1\n",
    "        h_g4 = conv2d_transpose(inputs=h_g3, filters=1, kernel_size=4, strides=2, name=\"g_deconv2\")\n",
    "        h_g4 = tf.layers.batch_normalization(h_g4, training=(not share))\n",
    "#         h_g3 = tf.nn.relu(h_g3)\n",
    "#         h_g3 = tf.layers.dropout(h_g3, rate=0.2)\n",
    "        \n",
    "#         # 14*14*128 to 28*28*1\n",
    "#         logits = tf.layers.conv2d_transpose(h_g3, filters=num_output, kernel_size=3, \n",
    "#                                             strides=2, padding='same')\n",
    "        \n",
    "        outputs = tf.nn.sigmoid(h_g4)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_g = np.random.uniform(-1, 1, size=(10, 100)).astype(np.float32)\n",
    "# yy = data_y[0:10].astype(np.float32)\n",
    "# tf.reset_default_graph()\n",
    "# kk = generator(in_g, yy, 1)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     a = sess.run(kk)\n",
    "#     print(a.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(data_img, share=False, alpha=0.2):\n",
    "    \n",
    "    ### data_img: the img to be classified\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=share):\n",
    "        # 28*28*1 to 14*14*64\n",
    "        h_g1 = conv2d(data_img, filters=64, kernel_size=4, strides=2, name='d_conv1')\n",
    "        h_g1 = tf.nn.leaky_relu(h_g1, alpha=alpha)\n",
    "#         h_g1 = tf.layers.dropout(h_g1, rate=0.2)\n",
    "        \n",
    "        # 14*14*64 to 7*7*128\n",
    "        h_g2 = conv2d(h_g1, filters=128, kernel_size=4, strides=2, name='d_conv2')\n",
    "        h_g2 = bn(h_g2, training=(not share))\n",
    "        h_g2 = tf.nn.leaky_relu(h_g2, alpha=alpha)\n",
    "#         h_g2 = tf.layers.dropout(h_g2, rate=0.2)\n",
    "        \n",
    "#         # 7*7*256 to 4*4*512\n",
    "#         h_g3 = tf.layers.conv2d(h_g2, filters=512, kernel_size=3, \n",
    "#                                 strides=2, padding='same')\n",
    "#         h_g3 = tf.layers.batch_normalization(h_g3, training=True)\n",
    "#         h_g3 = tf.nn.leaky_relu(h_g3, alpha=alpha)\n",
    "#         h_g3 = tf.layers.dropout(h_g3, rate=0.2)\n",
    "        \n",
    "        # FC\n",
    "        h_g_flatten = tf.reshape(h_g2, (-1, 7*7*128))\n",
    "        h_g_fc1 = linear(h_g_flatten, 1024)\n",
    "        h_g_fc1 = bn(h_g_fc1, training=(not share))\n",
    "        h_g_fc1 = tf.nn.leaky_relu(h_g_fc1, alpha=alpha)\n",
    "        \n",
    "        logits = linear(h_g_fc1, 1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "        \n",
    "        return logits, outputs, h_g_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(loss_g, loss_d, beta1=0.5, lr=0.0002):\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'generator' in var.name]\n",
    "    q_vars = [var for var in t_vars if ('discriminator' in var.name) \n",
    "              or ('generator' in var.name) or ('classifier' in var.name)]\n",
    "\n",
    "    # optimizer\n",
    "#     with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "        g_optimization = tf.train.AdamOptimizer(lr*5, \n",
    "                                    beta1=beta1).minimize(loss_g, var_list=g_vars)\n",
    "        d_optimization = tf.train.AdamOptimizer(lr,\n",
    "                                    beta1=beta1).minimize(loss_d, var_list=d_vars)\n",
    "        q_optimization = tf.train.AdamOptimizer(lr*5,\n",
    "                                    beta1=beta1).minimize(loss_d, var_list=q_vars)\n",
    "        return g_optimization, d_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(data_img, noise_img, y, image_depth):\n",
    "    \n",
    "#     noise_img = tf.Variable(np.random.uniform(-1, 1, size=(10, 100)).astype(np.float32))\n",
    "#     y = tf.Variable(data_y[0:10].astype(np.float32))\n",
    "#     data_img = tf.Variable(data_x[0:10].astype(np.float32))\n",
    "    \n",
    "    img_generated = generator(noise_img, y, image_depth, share=False)\n",
    "    logits_d_real, out_d_real, _ = discriminator(data_img)\n",
    "    logits_d_fake, out_d_fake, in_classifier = discriminator(img_generated, share=True)\n",
    "    logits_c_fake, c_fake  = classifier(in_classifier, share=False)\n",
    "    \n",
    "    # calculate\n",
    "    loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_d_fake,\n",
    "                                                    labels=tf.ones_like(out_d_fake)))\n",
    "    loss_d_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_d_real,\n",
    "                                                    labels=tf.ones_like(out_d_real)))\n",
    "    loss_d_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_d_fake,\n",
    "                                                    labels=tf.zeros_like(out_d_fake)))\n",
    "    \n",
    "    loss_d = tf.add(loss_d_fake, loss_d_real)\n",
    "    \n",
    "    \n",
    "    ## Information\n",
    "    #class loss\n",
    "    class_c_logits = logits_c_fake[:, :10]\n",
    "    class_y = y[:, :10]\n",
    "    q_class_loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=class_c_logits, labels=class_y))\n",
    "    \n",
    "    b_c_logits = logits_c_fake[:, 10:]\n",
    "    b_y = y[:, 10:]\n",
    "    q_b_loss = tf.reduce_mean(tf.reduce_sum(tf.square(b_y-b_c_logits),axis=1))\n",
    "    \n",
    "    loss_q = tf.add(q_class_loss,q_b_loss)\n",
    "    loss_q = q_class_loss\n",
    "    \n",
    "    \n",
    "    return loss_g, loss_d, loss_q\n",
    "# , logits_c_fake, c_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_g = tf.Variable(np.random.uniform(-1, 1, size=(10, 100)).astype(np.float32))\n",
    "# yy = tf.Variable(data_y[0:10].astype(np.float32))\n",
    "# xx = tf.Variable(data_x[0:10].astype(np.float32))\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# kk = loss(xx, in_g, yy, 1)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     a = sess.run(kk)\n",
    "# #     logits_c_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(samples):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=25, sharex=True, sharey=True, figsize=(50,2))\n",
    "    for img, ax in zip(samples, axes):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, inputs_noise, output_dim, y_, y_codes):\n",
    "    \n",
    "    cmap = 'Greys_r'\n",
    "    noise_shape = inputs_noise.get_shape().as_list()[-1]\n",
    "\n",
    "    examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])\n",
    "\n",
    "    samples = sess.run(generator(inputs_noise, y, output_dim, share=True),\n",
    "                       feed_dict={inputs_noise: examples_noise, y: y_codes})\n",
    "\n",
    "    \n",
    "    result = np.squeeze(samples, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.7\n",
    "# tf.GPUOptions(per_process_gpu_memory_fraction=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-7a102d807813>:28: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-8d0d6a04a6f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mreal_pic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_pic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mloss_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_pic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_pic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mg_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimize' is not defined"
     ]
    }
   ],
   "source": [
    "# batch\n",
    "batch_size = 64\n",
    "\n",
    "# epoch\n",
    "epochs = 5\n",
    "\n",
    "# num of samples\n",
    "num_sample = 10\n",
    "\n",
    "shape_noise = 100\n",
    "get_pic = []\n",
    "losses = []\n",
    "steps = 0\n",
    "tf.reset_default_graph()\n",
    "# inputs\n",
    "real_pic, noise_pic, y = set_input(shape_noise, [-1, 28, 28, 1])\n",
    "loss_g, loss_d, loss_q = loss(real_pic, noise_pic, y, 1)\n",
    "g_optimizer, d_optimizer, q_optimizer = optimize(loss_g, loss_d, loss_q)\n",
    "\n",
    "# save\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for i in range(num_train // batch_size):\n",
    "            steps +=1\n",
    "            pic_batch = data_x[i*batch_size:i*batch_size+batch_size]\n",
    "            pic_label = data_y[i*batch_size:i*batch_size+batch_size]\n",
    "            \n",
    "#             pic_batch = batch[0].reshape((batch_size, shape_img[1],\n",
    "#                                           shape_img[2], shape_img[3]))\n",
    "            pic_codes = np.concatenate((pic_label, \n",
    "                                        np.random.uniform(-1,1,size=(batch_size,2))),axis=1)\n",
    "\n",
    "            # input for the generator\n",
    "            in_g = np.random.uniform(-1, 1, size=(batch_size, shape_noise))\n",
    "\n",
    "            # Optimzer\n",
    "            _ = sess.run(d_optimizer, feed_dict={real_pic: pic_batch, noise_pic: in_g, y: pic_codes})\n",
    "            _, _ = sess.run([g_optimizer,q_optimizer], feed_dict={real_pic: pic_batch, noise_pic: in_g, y: pic_codes})\n",
    "\n",
    "\n",
    "#         print(\"Epoch {}/{}....\".format(e + 1, epochs),\n",
    "#               \"Discriminator Loss: {:.4f}....\".format(train_loss_d),\n",
    "#               \"Generator Loss: {:.4f}....\".format(train_loss_g))\n",
    "\n",
    "        # save the losses\n",
    "            if steps % 100 == 0:\n",
    "                        # loss\n",
    "                train_loss_d = sess.run(loss_d, feed_dict={real_pic: pic_batch, noise_pic: in_g, y: pic_codes})\n",
    "            #         train_loss_d_real = sess.run(loss_d1, feed_dict={real_pic: pic_batch,\n",
    "            #                                                    noise_pic: in_g})\n",
    "            #         train_loss_d_fake = sess.run(loss_d2, feed_dict={real_pic: pic_batch,\n",
    "            #                                                    noise_pic: in_g})\n",
    "\n",
    "                train_loss_g = sess.run(loss_g, feed_dict={real_pic: pic_batch, noise_pic: in_g, y: pic_codes})\n",
    "\n",
    "                samples = show_generator_output(sess, num_sample, noise_pic, shape_img[-1], y, pic_codes[0:10])\n",
    "                plot_images(samples)\n",
    "                get_pic.append(samples)\n",
    "                print(\"Epoch {}/{}....\".format(e+1, epochs), \n",
    "                          \"Discriminator Loss: {:.4f}....\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}....\". format(train_loss_g))\n",
    "#         losses.append((train_loss_d, train_loss_g))\n",
    "\n",
    "#         # get the images in differen phases\n",
    "#         in_sample = np.random.uniform(-1, 1, size=(num_sample, shape_noise))\n",
    "#         pic_generate = sess.run(generator(noise_pic,  shape_img[-1], share=True),\n",
    "#                                 feed_dict={noise_pic: in_sample})\n",
    "#         get_pic.append(pic_generate)\n",
    "#         # save the checkpoints for NN transfer\n",
    "        final_codes= get_y_code()\n",
    "        final_expamples = show_generator_output(sess, 100, noise_pic, shape_img[-1], y, final_codes)\n",
    "        saver.save(sess, '/check_NN/para_NN.ckpt')\n",
    "with open('samples_DCgan.pkl', 'wb') as f:\n",
    "    pickle.dump(get_pic, f)\n",
    "with open('samples_DCgan_final.pkl', 'wb') as f:\n",
    "    pickle.dump(final_expamples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_code():\n",
    "    y_example_code = np.zeros((100,12), dtype=np.float)\n",
    "    final_codes=[]\n",
    "    for k in range(10):\n",
    "        final_codes.append(list(k*np.ones(10)))\n",
    "    final_codes = np.array(final_codes)\n",
    "    final_codes = final_codes.reshape(100,-1)\n",
    "    for i,j in enumerate(final_codes):\n",
    "        y_example_code[i,int(j[0])]=1.0\n",
    "    return y_example_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('samples_DCgan_final.pkl', 'rb') as f:\n",
    "    pic_generate = pickle.load(f)\n",
    "    \n",
    "def show_pic_g2(epoch, samples):\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize = (20, 80), nrows=20, ncols=5, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples): # 这里samples[epoch][1]代表生成的图像结果，而[0]代表对应的logits\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_generate[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_pic_g2(1, pic_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
