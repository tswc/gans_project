{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow.examples.tutorials.mnist.input_data as mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input():\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x_in\")\n",
    "    y_ = tf.placeholder(\"float\", [None, 10], name=\"y_out\")\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    return x,y_,x_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init)\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        \n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init)\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        \n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024 )\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, out_model):\n",
    "    return -tf.reduce_sum(y_ * tf.log(out_model))\n",
    "\n",
    "def optimize(loss_tmin):\n",
    "    loss_optimize = tf.train.AdamOptimizer(1e-4).minimize(loss_tmin)\n",
    "    return loss_optimize\n",
    "\n",
    "def get_acc(y, out_model):\n",
    "    state_y = tf.equal(tf.argmax(y,1), tf.argmax(out_model,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "# accuracy = get_acc(y_, out_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = mnist.train.next_batch(50)\n",
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.21875\n",
      "step 101, training accuracy 0.921875\n",
      "step 201, training accuracy 0.953125\n",
      "step 301, training accuracy 0.984375\n",
      "step 401, training accuracy 0.96875\n",
      "step 501, training accuracy 0.96875\n",
      "step 601, training accuracy 0.953125\n",
      "step 701, training accuracy 0.96875\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.984375\n",
      "step 1001, training accuracy 0.953125\n",
      "step 1101, training accuracy 1\n",
      "step 1201, training accuracy 0.96875\n",
      "step 1301, training accuracy 0.984375\n",
      "step 1401, training accuracy 1\n",
      "step 1501, training accuracy 0.984375\n",
      "step 1601, training accuracy 0.96875\n",
      "step 1701, training accuracy 0.96875\n",
      "step 1801, training accuracy 1\n",
      "step 1901, training accuracy 1\n",
      "test accuracy 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    print(\"test accuracy %g\" % accuracy.eval(\n",
    "    feed_dict={x: mnist.test.images[0:100], y_: mnist.test.labels[0:100]}))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[0:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('samples_DCgan_final.pkl', 'rb') as f:\n",
    "    pic_generate = pickle.load(f)\n",
    "    \n",
    "pic_in = pic_generate.reshape(-1,28*28)\n",
    "pic_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('label_DCgan.pkl','rb') as f:\n",
    "    pic_label = pickle.load(f)\n",
    "\n",
    "\n",
    "pic_label_1h = np.zeros((100,10))\n",
    "pic_label_1h[np.arange(100), pic_label] = 1\n",
    "\n",
    "pic_label_1h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.359375\n",
      "step 101, training accuracy 0.96875\n",
      "step 201, training accuracy 0.984375\n",
      "step 301, training accuracy 0.96875\n",
      "step 401, training accuracy 1\n",
      "step 501, training accuracy 0.984375\n",
      "step 601, training accuracy 0.984375\n",
      "step 701, training accuracy 0.984375\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.953125\n",
      "test accuracy 0.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "#         if i%500==1:\n",
    "    print(\"test accuracy %g\" % accuracy.eval(\n",
    "    feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C_regu(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        pool1 = tf.layers.batch_normalization(pool1, training=True)\n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        pool2 = tf.layers.batch_normalization(pool2, training=True)\n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.4375\n",
      "test accuracy 0.33\n",
      "step 101, training accuracy 0.953125\n",
      "step 201, training accuracy 1\n",
      "step 301, training accuracy 1\n",
      "step 401, training accuracy 0.984375\n",
      "step 501, training accuracy 1\n",
      "test accuracy 0.93\n",
      "step 601, training accuracy 0.953125\n",
      "step 701, training accuracy 0.984375\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 1\n",
      "step 1001, training accuracy 0.984375\n",
      "test accuracy 0.94\n",
      "step 1101, training accuracy 0.984375\n",
      "step 1201, training accuracy 1\n",
      "step 1301, training accuracy 0.953125\n",
      "step 1401, training accuracy 1\n",
      "step 1501, training accuracy 1\n",
      "test accuracy 0.93\n",
      "step 1601, training accuracy 1\n",
      "step 1701, training accuracy 0.984375\n",
      "step 1801, training accuracy 0.984375\n",
      "step 1901, training accuracy 0.984375\n",
      "step 2001, training accuracy 1\n",
      "test accuracy 0.93\n",
      "step 2101, training accuracy 0.984375\n",
      "step 2201, training accuracy 1\n",
      "step 2301, training accuracy 1\n",
      "step 2401, training accuracy 1\n",
      "step 2501, training accuracy 1\n",
      "test accuracy 0.91\n",
      "step 2601, training accuracy 0.984375\n",
      "step 2701, training accuracy 1\n",
      "step 2801, training accuracy 1\n",
      "step 2901, training accuracy 0.984375\n",
      "step 3001, training accuracy 0.984375\n",
      "test accuracy 0.95\n",
      "step 3101, training accuracy 1\n",
      "step 3201, training accuracy 1\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 1\n",
      "step 3501, training accuracy 1\n",
      "test accuracy 0.93\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 0.96875\n",
      "step 3801, training accuracy 1\n",
      "step 3901, training accuracy 1\n",
      "step 4001, training accuracy 1\n",
      "test accuracy 0.94\n",
      "step 4101, training accuracy 1\n",
      "step 4201, training accuracy 0.984375\n",
      "step 4301, training accuracy 1\n",
      "step 4401, training accuracy 1\n",
      "step 4501, training accuracy 1\n",
      "test accuracy 0.94\n",
      "step 4601, training accuracy 0.109375\n",
      "step 4701, training accuracy 0.09375\n",
      "step 4801, training accuracy 0.078125\n",
      "step 4901, training accuracy 0.046875\n",
      "step 5001, training accuracy 0.046875\n",
      "test accuracy 0.1\n",
      "step 5101, training accuracy 0.140625\n",
      "step 5201, training accuracy 0.046875\n",
      "step 5301, training accuracy 0.109375\n",
      "step 5401, training accuracy 0.0625\n",
      "step 5501, training accuracy 0.09375\n",
      "test accuracy 0.1\n",
      "step 5601, training accuracy 0.125\n",
      "step 5701, training accuracy 0.109375\n",
      "step 5801, training accuracy 0.0625\n",
      "step 5901, training accuracy 0.15625\n",
      "step 6001, training accuracy 0.09375\n",
      "test accuracy 0.1\n",
      "step 6101, training accuracy 0.09375\n",
      "step 6201, training accuracy 0.046875\n",
      "step 6301, training accuracy 0.125\n",
      "step 6401, training accuracy 0.078125\n",
      "step 6501, training accuracy 0.09375\n",
      "test accuracy 0.1\n",
      "step 6601, training accuracy 0.078125\n",
      "step 6701, training accuracy 0.140625\n",
      "step 6801, training accuracy 0.109375\n",
      "step 6901, training accuracy 0.0625\n",
      "step 7001, training accuracy 0.109375\n",
      "test accuracy 0.1\n",
      "step 7101, training accuracy 0.09375\n",
      "step 7201, training accuracy 0.09375\n",
      "step 7301, training accuracy 0.140625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-85518e31a140>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#     a = sess.run(out_model,feed_dict={x: batch[0]})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     print(a.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_optimize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             train_accuracy = accuracy.eval(feed_dict={\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C_regu(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C_regu_dropconv(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1 = tf.layers.dropout(conv1, rate=0.2)\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        pool1 = tf.layers.batch_normalization(pool1, training=True)\n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2 = tf.layers.dropout(conv2, rate=0.2)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        pool2 = tf.layers.batch_normalization(pool2, training=True)\n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.453125\n",
      "test accuracy 0.3\n",
      "step 101, training accuracy 0.890625\n",
      "step 201, training accuracy 0.984375\n",
      "step 301, training accuracy 0.96875\n",
      "step 401, training accuracy 0.984375\n",
      "step 501, training accuracy 0.953125\n",
      "test accuracy 0.64\n",
      "step 601, training accuracy 0.96875\n",
      "step 701, training accuracy 0.984375\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.984375\n",
      "step 1001, training accuracy 1\n",
      "test accuracy 0.65\n",
      "step 1101, training accuracy 1\n",
      "step 1201, training accuracy 0.984375\n",
      "step 1301, training accuracy 0.984375\n",
      "step 1401, training accuracy 0.984375\n",
      "step 1501, training accuracy 1\n",
      "test accuracy 0.66\n",
      "step 1601, training accuracy 0.984375\n",
      "step 1701, training accuracy 0.984375\n",
      "step 1801, training accuracy 0.984375\n",
      "step 1901, training accuracy 0.984375\n",
      "step 2001, training accuracy 1\n",
      "test accuracy 0.68\n",
      "step 2101, training accuracy 1\n",
      "step 2201, training accuracy 1\n",
      "step 2301, training accuracy 1\n",
      "step 2401, training accuracy 1\n",
      "step 2501, training accuracy 0.96875\n",
      "test accuracy 0.65\n",
      "step 2601, training accuracy 0.984375\n",
      "step 2701, training accuracy 1\n",
      "step 2801, training accuracy 1\n",
      "step 2901, training accuracy 1\n",
      "step 3001, training accuracy 0.984375\n",
      "test accuracy 0.66\n",
      "step 3101, training accuracy 1\n",
      "step 3201, training accuracy 0.984375\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 0.984375\n",
      "step 3501, training accuracy 1\n",
      "test accuracy 0.66\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 1\n",
      "step 3801, training accuracy 1\n",
      "step 3901, training accuracy 1\n",
      "step 4001, training accuracy 1\n",
      "test accuracy 0.65\n",
      "step 4101, training accuracy 1\n",
      "step 4201, training accuracy 0.09375\n",
      "step 4301, training accuracy 0.09375\n",
      "step 4401, training accuracy 0.09375\n",
      "step 4501, training accuracy 0.046875\n",
      "test accuracy 0.18\n",
      "step 4601, training accuracy 0.078125\n",
      "step 4701, training accuracy 0.09375\n",
      "step 4801, training accuracy 0.0625\n",
      "step 4901, training accuracy 0.078125\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C_regu_dropconv(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(5000):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C_regu_dropconv_m(X):\n",
    "    with tf.variable_scope(\"classifier\"): \n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # layer1\n",
    "        conv1 = tf.layers.conv2d(X, filters=32, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1 = tf.layers.dropout(conv1, rate=0.2)\n",
    "        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2, padding=\"same\")\n",
    "        pool1 = tf.layers.batch_normalization(pool1, training=True)\n",
    "        # layer2\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, strides=1, padding=\"same\",kernel_initializer=w_init,bias_initializer=b_init,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2 = tf.layers.dropout(conv2, rate=0.2)\n",
    "        \n",
    "        pool2 = tf.layers.max_pooling2d(conv2,pool_size=2, strides=2)\n",
    "        pool2 = tf.layers.batch_normalization(pool2, training=True)\n",
    "        # layer3 FC\n",
    "        data_flatten = tf.reshape(pool2,(-1, 7*7*64))\n",
    "        dense1 = tf.layers.dense(data_flatten, 1024,\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(0.2))\n",
    "        dense1 = tf.layers.dropout(dense1, rate=0.5)\n",
    "        dense2 = tf.layers.dense(dense1, 10)\n",
    "        \n",
    "        out_model = tf.nn.softmax(dense2)\n",
    "        \n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1, training accuracy 0.515625\n",
      "test accuracy 0.38\n",
      "step 101, training accuracy 0.96875\n",
      "step 201, training accuracy 0.984375\n",
      "step 301, training accuracy 0.96875\n",
      "step 401, training accuracy 0.953125\n",
      "step 501, training accuracy 0.984375\n",
      "test accuracy 0.95\n",
      "step 601, training accuracy 0.953125\n",
      "step 701, training accuracy 0.96875\n",
      "step 801, training accuracy 0.984375\n",
      "step 901, training accuracy 0.953125\n",
      "step 1001, training accuracy 0.984375\n",
      "test accuracy 0.94\n",
      "step 1101, training accuracy 0.984375\n",
      "step 1201, training accuracy 1\n",
      "step 1301, training accuracy 1\n",
      "step 1401, training accuracy 0.984375\n",
      "step 1501, training accuracy 0.984375\n",
      "test accuracy 0.94\n",
      "step 1601, training accuracy 1\n",
      "step 1701, training accuracy 1\n",
      "step 1801, training accuracy 0.984375\n",
      "step 1901, training accuracy 1\n",
      "step 2001, training accuracy 1\n",
      "test accuracy 0.93\n",
      "step 2101, training accuracy 0.984375\n",
      "step 2201, training accuracy 0.984375\n",
      "step 2301, training accuracy 0.984375\n",
      "step 2401, training accuracy 0.984375\n",
      "step 2501, training accuracy 0.984375\n",
      "test accuracy 0.93\n",
      "step 2601, training accuracy 1\n",
      "step 2701, training accuracy 0.984375\n",
      "step 2801, training accuracy 1\n",
      "step 2901, training accuracy 1\n",
      "step 3001, training accuracy 0.96875\n",
      "test accuracy 0.95\n",
      "step 3101, training accuracy 1\n",
      "step 3201, training accuracy 1\n",
      "step 3301, training accuracy 1\n",
      "step 3401, training accuracy 1\n",
      "step 3501, training accuracy 1\n",
      "test accuracy 0.91\n",
      "step 3601, training accuracy 1\n",
      "step 3701, training accuracy 1\n",
      "step 3801, training accuracy 1\n",
      "step 3901, training accuracy 1\n",
      "step 4001, training accuracy 1\n",
      "test accuracy 0.94\n",
      "step 4101, training accuracy 1\n",
      "step 4201, training accuracy 0.171875\n",
      "step 4301, training accuracy 0.046875\n",
      "step 4401, training accuracy 0.140625\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x,y_,x_image = set_input()\n",
    "out_model = model_C_regu_dropconv_m(x_image)\n",
    "loss_model = loss(y_, out_model)\n",
    "sess_optimize = optimize(loss_model)\n",
    "\n",
    "# acc\n",
    "state_y = tf.equal(tf.argmax(y_,1), tf.argmax(out_model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(state_y, \"float\"))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(4501):\n",
    "        batch = mnist.train.next_batch(64)\n",
    "#     a = sess.run(out_model,feed_dict={x: batch[0]})\n",
    "#     print(a.shape)\n",
    "        _ = sess.run(sess_optimize,feed_dict={x: batch[0], y_:batch[1]})\n",
    "        if i%100==1:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "               x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        if i%500==1:\n",
    "            print(\"test accuracy %g\" % accuracy.eval(\n",
    "            feed_dict={x: pic_in, y_: pic_label_1h}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
